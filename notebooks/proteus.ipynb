{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## PQuant Proteus: Proteomics differential expression downstream analysis \n",
    "\n",
    "The following Jupyter notebooks allows to perform differential expression data analysis from multiple pipelines developed by the bigbio team. The output of the following pipelines are supported: \n",
    "\n",
    "- [proteomicsLFQ](https://github.com/nf-core/proteomicslfq): LFQ pipeline based on OpenMS and nextflow. \n",
    "\n",
    "The following Notebook uses [Proteus](http://www.compbio.dundee.ac.uk/user/mgierlinski/proteus/proteus.html) to perform the downstream data analysis of the data. Major steps in the data processing are the following: \n",
    "\n",
    "- Importing data from the pipeline. The major sources of data are:\n",
    "  - out.mzTab: The mzTab file format containing the PSMs, Peptides and proteins. \n",
    "  - out_msstats.csv: Input of MSstats. \n",
    "  - metadata.sdrf.tsv: File with the metadata sample information in [SDRF](https://github.com/bigbio/proteomics-metadata-standard). \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'\n",
    "msstats_output = '../data/MSstats_output.csv'\n",
    "msstats_input  = '../data/out_msstats.csv'\n",
    "mztab_input = '../data/out.mzTab'\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "from pyteomics import mztab\n",
    "\n",
    "\n",
    "def function(sequence, reference, evi_protein_group):\n",
    "    evi_sequence = []  # Total cleaning data\n",
    "    evi_modified_sequence = []\n",
    "    out_C = []\n",
    "    evi_modifications = []\n",
    "    evi_experiment = []\n",
    "\n",
    "    for i in range(0, len(csv_PeptideSequence)):\n",
    "        top = csv_PeptideSequence[i]\n",
    "        while \"(\" in top:\n",
    "            a = top.find('(')\n",
    "            b = top.find(')')\n",
    "            top = top.replace(top[a:b + 1], '')  # Replace the data in brackets with empty\n",
    "        result = re.sub('[\\W_\\d]+', '', top)  # Filter character\n",
    "        evi_sequence.append(result)\n",
    "        evi_experiment.append(reference[i][:-5])\n",
    "    #print(len(evi_sequence))\n",
    "    #print(len(evi_experiment))\n",
    "\n",
    "    for i in range(0, len(csv_PeptideSequence)):\n",
    "        top = csv_PeptideSequence[i]\n",
    "        k = csv_PeptideSequence[i]\n",
    "        date = \"_\"\n",
    "        #row = []\n",
    "        #col = []\n",
    "        next = 0\n",
    "        while \"(\" in top:\n",
    "            a = top.find('(')\n",
    "            b = top.find(')')\n",
    "            c = a + next\n",
    "            d = b + next\n",
    "            temp = k[c + 1:c + 3]  # Lowercase the first two strings\n",
    "            temp = temp.lower()\n",
    "            k = k.replace(k[c + 1:d], temp)\n",
    "            top = top.replace(top[a:b + 1], '')\n",
    "            next = 4\n",
    "        k = k.replace(\".\", '')\n",
    "        evi_modified_sequence.append(date + k + date)\n",
    "\n",
    "    \n",
    "    for i in range(0, len(csv_PeptideSequence)):\n",
    "        top = csv_PeptideSequence[i]\n",
    "        flag = True   # True means this line is unmodified\n",
    "        out_C = {}\n",
    "        while \"(\" in top:\n",
    "            flag = False\n",
    "            a = top.find('(')\n",
    "            b = top.find(')')\n",
    "            temp = top[a + 1: b]  # Storage modification\n",
    "            lent = len(top.split(temp)) - 1  # Modification occurrences\n",
    "            top = top.replace(top[a:b + 1], '')\n",
    "            out_C[temp] = lent\n",
    "        \n",
    "        # Convert dictionary to array\n",
    "        tem = []\n",
    "        for key, value in out_C.items():\n",
    "            if value == 1:  # If it only appears once, no need to display the number of occurrences\n",
    "                tem.append(key)\n",
    "            else:\n",
    "                tem.append(str(value) + ' ' + key)\n",
    "        tem = ','.join(tem)\n",
    "\n",
    "        if flag:\n",
    "            evi_modifications.append(\"Unmodified\")\n",
    "        else:\n",
    "            evi_modifications.append(tem)\n",
    "\n",
    "    evi_protein = []\n",
    "    for i in range(0, len(evi_protein_group)):\n",
    "        protein_group = evi_protein_group[i]\n",
    "        if \";\" in protein_group:\n",
    "            semicolon = protein_group.index(';')\n",
    "            evi_protein.append(protein_group[:semicolon])\n",
    "        else:\n",
    "            evi_protein.append(protein_group)\n",
    "\n",
    "    return evi_sequence, evi_modified_sequence, evi_modifications, evi_experiment, evi_protein\n",
    "\n",
    "\n",
    "def get_mztab(pri_mztab, data_dir):\n",
    "    #df_pri = pd.read_csv(pri_mztab)\n",
    "    out_mzTab_path = pri_mztab\n",
    "    mztab_data = mztab.MzTab(out_mzTab_path)\n",
    "    pep_table = mztab_data.peptide_table\n",
    "    df_pri = pep_table\n",
    "\n",
    "    df_pri.to_csv(data_dir + '/pep.csv', index=False)\n",
    "\n",
    "    return ''\n",
    "\n",
    "\n",
    "\n",
    "# TODO These code implements data processing\n",
    "get_mztab(mztab_input, data_dir)\n",
    "\n",
    "mztab = data_dir + \"/pep.csv\"\n",
    "    \n",
    "df_csv = pd.read_csv(msstats_input)\n",
    "df_mztab = pd.read_csv(mztab)\n",
    "\n",
    "csv_PeptideSequence = df_csv['PeptideSequence']\n",
    "csv_ProteinName = df_csv['ProteinName']\n",
    "csv_experiment = df_csv['Reference']\n",
    "csv_PrecursorCharge = df_csv['PrecursorCharge']\n",
    "csv_intensity = df_csv['Intensity']\n",
    "\n",
    "evi_protein_group = csv_ProteinName\n",
    "evi_charge = csv_PrecursorCharge\n",
    "evi_intensity = csv_intensity\n",
    "\n",
    "\n",
    "evi_sequence, evi_modified_sequence, evi_modifications, evi_experiment, evi_protein = function(csv_PeptideSequence, csv_experiment, evi_protein_group)\n",
    "evidence = pd.DataFrame({\n",
    "    \"PeptideSequence\": evi_sequence,\n",
    "    \"modified_sequence\": evi_modified_sequence,\n",
    "    \"modifications\": evi_modifications,\n",
    "    \"protein_group\": evi_protein_group,\n",
    "    \"protein\": evi_protein,\n",
    "    \"experiment\": evi_experiment,\n",
    "    \"charge\": evi_charge,\n",
    "    \"intensity\": evi_intensity})\n",
    "evidence.to_csv(data_dir + \"/result_1.csv\")\n",
    "    \n",
    "# TODOï¼šThe following code implements the VLOOKUP function operation\n",
    "data_text = data_dir + \"/result_1.csv\"\n",
    "pep_text = data_dir + \"/pep.csv\"\n",
    "pep = pd.read_csv(pep_text)\n",
    "df = pd.read_csv(data_text)\n",
    "data = df[\"PeptideSequence\"]\n",
    "Pep = pep[[\"sequence\", \"accession\"]]\n",
    "Pep = Pep.drop_duplicates(subset=\"sequence\")  # De-duplicate the second table\n",
    "    \n",
    "df_merge = pd.merge(left=df, right=Pep, left_on=\"PeptideSequence\", right_on=\"sequence\", how='left', )\n",
    "\n",
    "\n",
    "if df_merge.columns[0] != 'PeptideSequence':\n",
    "    tmp = df_merge.iloc[:,1:len(df_merge.columns)]  # Deletes additional data in the first column that is not known when it was generated\n",
    "    df_merge = tmp\n",
    "        #print(df_merge)\n",
    "\n",
    "df_merge.to_csv(data_dir + \"/out_proteus.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 800 -h 600\n",
    "\n",
    "library(dplyr)\n",
    "library(proteus)\n",
    "\n",
    "path_proteus = '../data/out_proteus.csv'\n",
    "\n",
    "# generate Proteus evidence file\n",
    "evi <- readEvidenceFile(path_proteus,\n",
    "                        data.cols = updateEvidenceColumns(),\n",
    "                        measure.cols = updateMeasureColumns())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
